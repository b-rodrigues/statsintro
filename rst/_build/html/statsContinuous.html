

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Distribution of a Sample Mean &mdash; Introduction to Statistics 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Introduction to Statistics 1.0 documentation" href="index.html" />
    <link rel="next" title="One Proportion" href="statsCategorical.html" />
    <link rel="prev" title="Hypothesis tests" href="statsTests.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="statsCategorical.html" title="One Proportion"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="statsTests.html" title="Hypothesis tests"
             accesskey="P">previous</a> |</li>
        <li><a href="StatsFH.html">Introduction to Statistics 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <img alt="..\Images\title_continuous.png" src="..\Images\title_continuous.png" style="height: 100px;" />
<div class="section" id="distribution-of-a-sample-mean">
<h1>Distribution of a Sample Mean<a class="headerlink" href="#distribution-of-a-sample-mean" title="Permalink to this headline">¶</a></h1>
<div class="section" id="one-sample-t-test-for-a-mean-value">
<h2>One sample t-test for a mean value<a class="headerlink" href="#one-sample-t-test-for-a-mean-value" title="Permalink to this headline">¶</a></h2>
<p>If we knew the mean and the standard deviation of a normally distributed
population, we would know exactly the standard error, and use values
from the normal distribution to determine how likely it is to find a
certain mean value, given the population mean and standard deviation.
However, in practice we have to <em>estimate</em> the mean and standard
deviation from the sample, and the resulting distribution for the mean
value deviates slightly from a normal distribution. Such distributions
are called <em>t-distributions</em>, and were first described by a researcher
working under the pseudonym of &#8220;Student&#8221;.</p>
<p>Let us look at a specific example: we take 100 normally distributed
data, with a mean of 7 and with a standard deviation of 3. What is the
chance of finding a mean value at a distance of 0.5 or more from the
mean:?</p>
<p>See also the ipython notebook <a class="reference external" href="http://nbviewer.ipython.org/url/work.thaslwanter.at/CSS/Code/ttest_1samp_notebook.ipynb">ttest_1samp_notebook.ipynb</a>:</p>
<p><span class="math">\(&gt;&gt;&gt;\)</span> The probability from the t-test is 0.057, and from the
normal distribution 0.054</p>
</div>
<div class="section" id="wilcoxon-signed-rank-sum-test">
<h2>Wilcoxon signed rank sum test<a class="headerlink" href="#wilcoxon-signed-rank-sum-test" title="Permalink to this headline">¶</a></h2>
<p>If our data are not normally distributed, we cannot use the t-test
(although this test is fairly robust against deviations from normality).
Instead, we must use a <em>non-parametric</em> test on the mean value. We can
do this by performing a <em>Wilcoxon signed rank sum test</em>.  <a class="footnote-reference" href="#id3" id="id1">[2]</a>  <a class="footnote-reference" href="#id4" id="id2">[3]</a>
This method has three steps:</p>
<ol class="arabic simple">
<li>Calculate the difference between each observation and the value of
interest.</li>
<li>Ignoring the signs of the differences, rank them in order of
magnitude.</li>
<li>Calculate the sum of the ranks of all the negative (or positive)
ranks, corresponding to the observations below (or above) the chosen
hypothetical value.</li>
</ol>
<p>In Table [tab:wilcoxon] you see an example, where the significance to a
deviation from the value of 7725 is tested. The rank sum of the negative
values gives <span class="math">\(3+5=8\)</span>, and can be looked up in the corresponding
tables to be significant. In practice, your computer program will
nowadays do this for you. This example also shows another feature of
rank evaluations: tied values (here <span class="math">\(7515\)</span>) get accorded their
mean rank (here <span class="math">\(1.5\)</span>).</p>
<table border="1" class="docutils">
<colgroup>
<col width="9%" />
<col width="32%" />
<col width="31%" />
<col width="28%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Subject</th>
<th class="head">Daily energy intake (kJ)</th>
<th class="head">Difference from 7725 kJ</th>
<th class="head">Ranks of differences</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>1</td>
<td>5260</td>
<td>2465</td>
<td>11</td>
</tr>
<tr class="row-odd"><td>2</td>
<td>5470</td>
<td>2255</td>
<td>10</td>
</tr>
<tr class="row-even"><td>3</td>
<td>5640</td>
<td>2085</td>
<td>9</td>
</tr>
<tr class="row-odd"><td>4</td>
<td>6180</td>
<td>1545</td>
<td>8</td>
</tr>
<tr class="row-even"><td>5</td>
<td>6390</td>
<td>1335</td>
<td>7</td>
</tr>
<tr class="row-odd"><td>6</td>
<td>6515</td>
<td>1210</td>
<td>6</td>
</tr>
<tr class="row-even"><td>7</td>
<td>6805</td>
<td>920</td>
<td>4</td>
</tr>
<tr class="row-odd"><td>8</td>
<td>7515</td>
<td>210</td>
<td>1.5</td>
</tr>
<tr class="row-even"><td>9</td>
<td>7515</td>
<td>210</td>
<td>1.5</td>
</tr>
<tr class="row-odd"><td>10</td>
<td>8230</td>
<td>-505</td>
<td>3</td>
</tr>
<tr class="row-even"><td>11</td>
<td>8770</td>
<td>-1045</td>
<td>5</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="comparison-of-two-groups">
<h1>Comparison of Two Groups<a class="headerlink" href="#comparison-of-two-groups" title="Permalink to this headline">¶</a></h1>
<p>When you compare two groups with each other, we have to distinguish
between two cases. In the first case, we compare two values recorded
from the same subject at two specific times. For example, we measure the
size of students when they enter primary school and after their first
year, and check if they have been growing. Since we are only interested
in the <em>difference</em> between the first and the second measurement, this
test is called <em>paired t-test</em>, and is essentially equivalent to a
one-sample t-test for the mean difference.</p>
<p>The second test is if we compare two independent groups. For example, we
can compare the effect of a two medications given to two different
groups of patients, and compare how the two groups respond. This is
called an <em>unpaired t-test</em>, or <em>t-test for two independent groups</em>.</p>
<p>If we have two independent samples the variance of the difference
between their means is the <em>sum</em> of the separate variances, so the
standard error of the difference in means is the square root of the sum
of the separate variances:</p>
<div class="math">
\[\begin{split}\begin{aligned}
   se({{\bar x}_1} - {{\bar x}_2}) &amp;= \sqrt {\operatorname{var} ({{\bar x}_1}) + \operatorname{var} ({{\bar x}_2})}  \\
   &amp;= \sqrt {{{\left\{ {se({{\bar x}_1})} \right\}}^2} + {{\left\{ {se({{\bar x}_2})} \right\}}^2}}  \\
   &amp;= \sqrt {\frac{{s_1^2}}{{{n_1}}} + \frac{{s_2^2}}{{{n_2}}}}  \\\end{aligned}\end{split}\]</div>
<p>where <span class="math">\(\bar{x}_i\)</span> is the mean of the i-th sample, and <em>se</em>
indicates the <em>standard error</em>.</p>
<p>See also the ipython notebook <a class="reference external" href="http://nbviewer.ipython.org/url/work.thaslwanter.at/Stats/ipynb/univariate.ipynb">univariate.ipynb</a>:</p>
<div class="section" id="non-parametric-comparison-of-two-groups-mann-whitney-test">
<h2>Non-parametric Comparison of Two Groups: Mann-Whitney Test<a class="headerlink" href="#non-parametric-comparison-of-two-groups-mann-whitney-test" title="Permalink to this headline">¶</a></h2>
<p>If the measurement values from the two groups are not normally
distributed we have to resort to a non-parametric test. The most common
test for that is the <em>Mann-Whitney(-Wilkoxon) test</em>.</p>
</div>
</div>
<div class="section" id="comparison-of-more-groups">
<h1>Comparison of More Groups<a class="headerlink" href="#comparison-of-more-groups" title="Permalink to this headline">¶</a></h1>
<div class="section" id="analysis-of-variance">
<h2>Analysis of Variance<a class="headerlink" href="#analysis-of-variance" title="Permalink to this headline">¶</a></h2>
<p>If we want to compare three or more groups with each other, we need to
use a <em>one way analysis of variance (ANOVA)</em>, sometimes also called a
<em>one factor ANOVA</em>. Because the null hypothesis is that there is no
difference between the groups, the test is based on a comparison of the
observed variation between the groups (i.e. between their means) with
that expected from the observed variability between subjects. The
comparison takes the general form of an <em>F test</em> to compare variances,
but for two groups the t test leads to exactly the same answer. We will
discuss ANOVAs in more detail in chapter [sec:anova].</p>
<div class="section" id="f-test">
<h3>F Test<a class="headerlink" href="#f-test" title="Permalink to this headline">¶</a></h3>
<p>The <span class="math">\(F\)</span> test or <em>variance ratio test</em> is very simple. Under the
null hypothesis that two Normally distributed populations have equal
variances we expect the ratio of the two sample variances to have an <em>F
distribution</em> (see section [sec:ContinuousDistributions]).</p>
</div>
<div class="section" id="bonferroni-correction">
<h3>Bonferroni correction<a class="headerlink" href="#bonferroni-correction" title="Permalink to this headline">¶</a></h3>
<p>If an ANOVA yields a significant result, we have to test which of the
groups are different. Typically, this is done with <span class="math">\(t-tests\)</span>.
Since we perform multiple t tests, we should compensate for the risk of
getting a significant result, even if our null hypothesis is true. The
simplest - and at the same time quite conservative - approach is to
divide the required p-value by the number of tests that we do
(<em>Bonferroni correction</em>). For example, if you perform 4 comparisons,
you check for significance not at <span class="math">\(p=0.05\)</span>, but at
<span class="math">\(p=0.0125\)</span>.</p>
<p>While multiple testing is not yet included in Python standardly, you can
get a number of multiple-testing corrections done with the statsmodels
package:</p>
<div class="highlight-python"><pre>In[7]: from statsmodels.sandbox.stats.multicomp import multipletests
In[8]: multipletests([.05, 0.3, 0.01], method='bonferroni')
Out[8]:
(array([False, False,  True], dtype=bool),
array([ 0.15,  0.9 ,  0.03]),
0.016952427508441503,
0.016666666666666666)</pre>
</div>
</div>
</div>
<div class="section" id="kruskal-wallis-test">
<h2>Kruskal-Wallis test<a class="headerlink" href="#kruskal-wallis-test" title="Permalink to this headline">¶</a></h2>
<p>Just as analysis of variance is a more general form of <span class="math">\(t\)</span> test,
so there is a more general form of the non-parametric Mann-whitney test:
the <em>Kruskal-Wallis test</em>. When the null hypothesis is true the test
statistic follows the <em>Chi squared distribution</em>.
See also the ipython notebook <a class="reference external" href="http://nbviewer.ipython.org/url/work.thaslwanter.at/CSS/Code/anovat.ipynb">anovat.ipynb</a>:</p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[2]</a></td><td>Python Example: scipy.stats.wilcoxon, in &#8220;univariate.py&#8221;</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[3]</a></td><td>The following description and example has been taken from Altman, Table 9.2</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="StatsFH.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Distribution of a Sample Mean</a><ul>
<li><a class="reference internal" href="#one-sample-t-test-for-a-mean-value">One sample t-test for a mean value</a></li>
<li><a class="reference internal" href="#wilcoxon-signed-rank-sum-test">Wilcoxon signed rank sum test</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparison-of-two-groups">Comparison of Two Groups</a><ul>
<li><a class="reference internal" href="#non-parametric-comparison-of-two-groups-mann-whitney-test">Non-parametric Comparison of Two Groups: Mann-Whitney Test</a></li>
</ul>
</li>
<li><a class="reference internal" href="#comparison-of-more-groups">Comparison of More Groups</a><ul>
<li><a class="reference internal" href="#analysis-of-variance">Analysis of Variance</a><ul>
<li><a class="reference internal" href="#f-test">F Test</a></li>
<li><a class="reference internal" href="#bonferroni-correction">Bonferroni correction</a></li>
</ul>
</li>
<li><a class="reference internal" href="#kruskal-wallis-test">Kruskal-Wallis test</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="statsTests.html"
                        title="previous chapter">Hypothesis tests</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="statsCategorical.html"
                        title="next chapter">One Proportion</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/statsContinuous.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="statsCategorical.html" title="One Proportion"
             >next</a> |</li>
        <li class="right" >
          <a href="statsTests.html" title="Hypothesis tests"
             >previous</a> |</li>
        <li><a href="StatsFH.html">Introduction to Statistics 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright March 2013, Thomas Haslwanter.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2.
    </div>
  </body>
</html>